from typing import List, Literal, Tuple
import os
import json
from datetime import datetime
from pathlib import Path
import re

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from openai import OpenAI

# ========== 
# FastAPI ã‚¢ãƒ—ãƒª 
# ==========
app = FastAPI(
    title="Talk Assist API",
    description="LINEãƒˆãƒ¼ã‚¯è¦ç´„ï¼†è¿”ä¿¡ç”ŸæˆAPI",
    version="0.1.0",
)

# CORSï¼ˆFlutter Web ã‚„ä»–ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚‚æƒ³å®šã—ã¦ç·©ã‚ã«è¨±å¯ï¼‰
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # æœ¬ç•ªã§å¿…è¦ãªã‚‰ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’çµã‚‹
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ========== 
# OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ 
# ==========
api_key = os.environ.get("OPENAI_API_KEY")
if not api_key:
    # èµ·å‹•æ™‚ã«æ°—ã¥ã‘ã‚‹ã‚ˆã†ã«æ˜ç¤ºçš„ã«è½ã¨ã™
    raise RuntimeError("OPENAI_API_KEY is not set in environment variables.")

client = OpenAI(api_key=api_key)

MODEL_NAME = "gpt-4.1-mini"

# ========== 
# é•·æ–‡å¯¾ç­–ç”¨ã®ã—ãã„å€¤ 
# ==========
# ç”Ÿãƒ†ã‚­ã‚¹ãƒˆã®ãƒãƒ¼ãƒ‰ä¸Šé™ï¼ˆã“ã‚Œã‚’è¶…ãˆãŸã‚‰ã¾ãšé ­+å°»ã ã‘ã«ãƒˆãƒªãƒ ï¼‰
MAX_RAW_CHARS = 8000
# ãƒ¢ãƒ‡ãƒ«ã«æ¸¡ã™æ–‡å­—æ•°ã®ç›®å®‰
MAX_USED_CHARS = 4000

# ========== 
# ãƒ­ã‚°è¨­å®šï¼ˆç°¡æ˜“ï¼‰ 
# ==========
LOG_DIR = Path("logs")
LOG_DIR.mkdir(exist_ok=True)
LOG_FILE = LOG_DIR / "talk_assist.log"


def write_log(record: dict) -> None:
    """ã‚¨ãƒ©ãƒ¼ã«ãªã£ã¦ã‚‚å‡¦ç†ã‚’æ­¢ã‚ãªã„ã€è¶…ç°¡æ˜“ãƒ­ã‚°"""
    try:
        record = {**record}
        record["ts"] = datetime.utcnow().isoformat()
        with LOG_FILE.open("a", encoding="utf-8") as f:
            f.write(json.dumps(record, ensure_ascii=False) + "\n")
    except Exception:
        # ãƒ­ã‚°å¤±æ•—ã¯é»™æ®º
        pass


# ========== 
# ãƒ¢ãƒ‡ãƒ« I/O ç”¨å‹ 
# ==========
ToneLiteral = Literal["standard", "night", "business"]


class TalkRequest(BaseModel):
    text: str
    tone: str = "standard"  # 'standard' | 'night' | 'business'


class TalkResponse(BaseModel):
    summary: str
    replies: List[str]


# ========== 
# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé–¢é€£ 
# ==========

def build_tone_desc_and_temp(tone: ToneLiteral) -> Tuple[str, float]:
    """ãƒˆãƒ¼ãƒ³åˆ¥ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆèª¬æ˜ã¨ temperature ã‚’è¿”ã™"""
    if tone == "night":
        tone_desc = (
            "ãƒˆãƒ¼ãƒ³: nightï¼ˆå¤œè·å‘ã‘ã®å–¶æ¥­LINEï¼‰\n"
            "\n"
            "# æƒ³å®šã‚·ãƒ¼ãƒ³\n"
            "- ã‚­ãƒ£ãƒã‚¯ãƒ© / ãƒ©ã‚¦ãƒ³ã‚¸ / ã‚¬ãƒ¼ãƒ«ã‚ºãƒãƒ¼ / ãƒ›ã‚¹ãƒˆç­‰ã®å–¶æ¥­LINEã‚’æƒ³å®šã—ã¦ãã ã•ã„ã€‚\n"
            "- æ—¢ã«ä¸€åº¦ä¼šã£ãŸãŠå®¢æ§˜ã¸ã®ãŠç¤¼ã€æ¬¡å›ã®æ¥åº—ãƒ»åŒä¼´ãƒ»æŒ‡åã®ææ¡ˆã€é›‘è«‡ã§é–¢ä¿‚æ€§ã‚’æ·±ã‚ã‚‹LINEãŒä¸­å¿ƒã§ã™ã€‚\n"
            "\n"
            "# ã‚´ãƒ¼ãƒ«\n"
            "- ã€æœ€å„ªå…ˆã€‘ãŠå®¢æ§˜ã«ã€ã“ã®å­ï¼ˆã“ã®äººï¼‰ã¨LINEã—ã¦ã‚‹ã¨æ¥½ã—ã„ã€ã€ã¾ãŸä¼šã„ãŸã„ã€ã¨æ€ã£ã¦ã‚‚ã‚‰ã†ã“ã¨ã€‚\n"
            "- ãã®ã†ãˆã§ã€ç„¡ç†ã®ãªã„ç¯„å›²ã§ã€Œæ¬¡ã«ä¼šã†ç´„æŸã€ã‚„ã€ŒãŠåº—ã«æ¥ã‚‹ãã£ã‹ã‘ã€ã‚’ä½œã‚‹ã“ã¨ã€‚\n"
            "\n"
            "# ãƒˆãƒ¼ãƒ³ãƒ»æ–‡ä½“\n"
            "- åŸºæœ¬ã¯ã‚¿ãƒ¡å£ã€œã‚†ã‚‹ã„æ•¬èªã§OKã§ã™ï¼ˆä¾‹: ã€Œã€œã‚„ã§ã€ã€Œã€œã ã‚ˆã€ã€Œã€œã§ã™ç¬‘ã€ãªã©ï¼‰ã€‚\n"
            "- ç›¸æ‰‹ã®ãƒˆãƒ¼ã‚¯å±¥æ­´ã«åˆã‚ã›ã¦ã€ä¸å¯§ã‚ / ç •ã‘ãŸå£èª¿ / é–¢è¥¿å¼ ãªã©ã‚’è‡ªç„¶ã«å¯„ã›ã¦ãã ã•ã„ã€‚\n"
            "- çµµæ–‡å­—ãƒ»é¡”æ–‡å­—ã¯ 1ã€œ3 å€‹ã¾ã§ã«æŠ‘ãˆã€é€£æŠ•ã—ãªã„ã§ãã ã•ã„ï¼ˆä¾‹: ã€ŒğŸ¥ºğŸ¥ºğŸ¥ºğŸ¥ºã€ã®ã‚ˆã†ãªå¤šç”¨ã¯é¿ã‘ã‚‹ï¼‰ã€‚\n"
            "- 1é€šã®é•·ã•ã¯ã€LINEã®ç”»é¢1ã€œ3ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ä»¥å†…ã«åã¾ã‚‹ã‚ˆã†ã€èª­ã¿ã‚„ã™ã„åŒºåˆ‡ã‚Šã§æ”¹è¡Œã—ã¦ãã ã•ã„ã€‚\n"
            "\n"
            "# å–¶æ¥­ã¨ã—ã¦ã®æŒ¯ã‚‹èˆã„\n"
            "- åŸºæœ¬ã¯ã€ç›¸æ‰‹ã‚’è¤’ã‚ã‚‹ã€ã€æ¥½ã—ã‹ã£ãŸãƒ»å¬‰ã—ã‹ã£ãŸã€ãªã©ã®ãƒã‚¸ãƒ†ã‚£ãƒ–ãªæ„Ÿæƒ…ã‚’ç´ ç›´ã«ä¼ãˆã¾ã™ã€‚\n"
            "- æ¥åº—ã‚„åŒä¼´ã®ææ¡ˆã¯ã€ã€ŒæŠ¼ã—ã¤ã‘ã€ã§ã¯ãªãã€Œææ¡ˆãƒ»ãŠèª˜ã„ã€ã®å½¢ã§æŸ”ã‚‰ã‹ãæ›¸ã„ã¦ãã ã•ã„ã€‚\n"
            "- ç›¸æ‰‹ãŒã€ä»Šæ—¥ã¯è¡Œã‘ãªã„ã€ã€ãŠé‡‘ãŒãã¤ã„ã€ãªã©æ–­ã‚Šæ°—å‘³ã®ã¨ãã¯ã€ç„¡ç†ã«èª˜ã‚ãš\n"
            "  ãƒ»ç†è§£ã‚’ç¤ºã™\n"
            "  ãƒ»è»½ã„å†—è«‡ã‚„æ—¥å¸¸è©±ã§é›°å›²æ°—ã‚’å’Œã‚‰ã’ã‚‹\n"
            "  ãƒ»ã€ã¾ãŸã‚¿ã‚¤ãƒŸãƒ³ã‚°åˆã†ã¨ãã§ã„ã„ã‚ˆã€ã¨ãƒ•ã‚©ãƒ­ãƒ¼ã™ã‚‹\n"
            "  ã‚’å„ªå…ˆã—ã¦ãã ã•ã„ã€‚\n"
            "- ãŠåº—ã®ãƒ«ãƒ¼ãƒ«ã‚’ç ´ã‚‹ã‚ˆã†ãªè¡¨ç¾ï¼ˆç„¡æ–­ã‚¢ãƒ•ã‚¿ãƒ¼ã€å‡ºå‹¤æ—¥ä»¥å¤–ã®ç„¡ç†ãªç´„æŸãªã©ï¼‰ã¯ææ¡ˆã—ãªã„ã§ãã ã•ã„ã€‚\n"
            "- é‡‘é¡ã‚„ãƒ—ãƒ¬ã‚¼ãƒ³ãƒˆã‚’å¼·è¦ã™ã‚‹ã‚ˆã†ãªè¡¨ç¾ã¯ä½¿ã‚ãªã„ã§ãã ã•ã„ã€‚\n"
            "\n"
            "# ãŠå®¢æ§˜ã®æ¸©åº¦æ„Ÿã®èª­ã¿å–ã‚Š\n"
            "- ãƒˆãƒ¼ã‚¯å±¥æ­´ã‹ã‚‰ã€ãŠå®¢æ§˜ã®æ¸©åº¦ã‚’ã–ã£ãã‚Šåˆ¤å®šã—ã¦ãã ã•ã„ã€‚\n"
            "  ãƒ»ãƒãƒªãŒè‰¯ãã€å‰å‘ããªè¿”äº‹ãŒå¤šã„ â†’ æ¸©åº¦ã€Œé«˜ã‚ã€\n"
            "  ãƒ»è¿”äº‹ã¯ã‚ã‚‹ãŒã€ã‚¹ã‚¿ãƒ³ãƒ—ã‚„çŸ­æ–‡ãŒå¤šã„ â†’ æ¸©åº¦ã€Œæ™®é€šã€\n"
            "  ãƒ»æ–­ã‚ŠãŒã¡ / è¿”ä¿¡ãŒé…ã„ / æ—¢èª­ã®ã¿ãŒå¤šã„ â†’ æ¸©åº¦ã€Œä½ã‚ã€\n"
            "- æ¸©åº¦ã€Œé«˜ã‚ã€ã®å ´åˆ: æ¬¡å›ã®å…·ä½“çš„ãªäºˆå®šï¼ˆå€™è£œæ—¥ã‚„ã‚¤ãƒ™ãƒ³ãƒˆï¼‰ã‚’è»½ãææ¡ˆã—ã¦OKã§ã™ã€‚\n"
            "- æ¸©åº¦ã€Œæ™®é€šã€ã®å ´åˆ: ç„¡ç†ã«æ—¥ç¨‹ã‚’æŠ¼ã—ã¤ã‘ãšã€ã€ã¾ãŸä¼šãˆãŸã‚‰å¬‰ã—ã„ãªã€ãƒ¬ãƒ™ãƒ«ã®ãµã‚“ã‚ã‚Šææ¡ˆã«ç•™ã‚ã¦ãã ã•ã„ã€‚\n"
            "- æ¸©åº¦ã€Œä½ã‚ã€ã®å ´åˆ: æ¥åº—ã®ææ¡ˆã¯æ§ãˆã‚ã«ã—ã¦ã€é›‘è«‡ãƒ»æ„Ÿè¬ãƒ»ç›¸æ‰‹ã®è² æ‹…ã«ãªã‚‰ãªã„è©±é¡Œã‚’å„ªå…ˆã—ã¦ãã ã•ã„ã€‚\n"
            "\n"
            "# è¿”ä¿¡æ¡ˆ3ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å½¹å‰²\n"
            "- è¿”ä¿¡æ¡ˆ1: ä¸€ç•ªå®‰å¿ƒæ„Ÿã®ã‚ã‚‹å–¶æ¥­LINE\n"
            "  ãƒ»ä¸å¯§ã‚ã§ã€ç›¸æ‰‹ã«ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ã‚’ã‹ã‘ãªã„\n"
            "  ãƒ»ãŠç¤¼ã‚„æ°—é£ã„ã‚’ã—ã£ã‹ã‚Šä¼ãˆã‚‹\n"
            "- è¿”ä¿¡æ¡ˆ2: å°‘ã—ç”˜ã‚ã§è·é›¢ã‚’ç¸®ã‚ã‚‹LINE\n"
            "  ãƒ»è»½ã„å†—è«‡ã‚„ã‚ã åã€å°‘ã—ã ã‘ç”˜ã„è¡¨ç¾ã‚’å…¥ã‚Œã¦OK\n"
            "  ãƒ»ãŸã ã—ã€ç›¸æ‰‹ã‚’ä¸å¿«ã«ã•ã›ã‚‹ã‚ˆã†ãªéåº¦ãªä¸‹ãƒã‚¿ã‚„é‡ã•ã¯é¿ã‘ã‚‹\n"
            "- è¿”ä¿¡æ¡ˆ3: æ¬¡ã«ä¼šã†ç´„æŸã«ã¤ãªãŒã‚‹LINE\n"
            "  ãƒ»ã€ã¾ãŸâ—¯â—¯è¡ŒããŸã„ã€ã€ä»Šåº¦â—¯æ›œæ—¥ç©ºã„ã¦ãŸã‚Šã™ã‚‹ï¼Ÿã€ãªã©ã€å…·ä½“çš„ãªä¸€æ­©ã‚’ææ¡ˆ\n"
            "  ãƒ»ãŸã ã—ã€ç›¸æ‰‹ãŒæ–­ã‚Šæ°—å‘³ã®ã¨ãã¯ã€ã€Œã„ã¤ã‹ã‚¿ã‚¤ãƒŸãƒ³ã‚°åˆã£ãŸã‚‰ã€ã§è»½ãæ¿ã™å½¢ã«ã—ã¦ãã ã•ã„ã€‚\n"
        )
        temperature = 0.8
    elif tone == "business":
        tone_desc = (
            "ãƒˆãƒ¼ãƒ³: businessï¼ˆãƒ“ã‚¸ãƒã‚¹ãƒãƒ£ãƒƒãƒˆï¼‰\n"
            "- ä¸Šå¸ãƒ»åŒåƒšãƒ»é¡§å®¢ãƒ»å–å¼•å…ˆã¨ã®ãƒ“ã‚¸ãƒã‚¹ãƒãƒ£ãƒƒãƒˆã‚’æƒ³å®šã—ã¦ãã ã•ã„ã€‚\n"
            "- ä¸å¯§ã§ç°¡æ½”ã€äº‹å®Ÿãƒ™ãƒ¼ã‚¹ã§ã€çµè«–ãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆã‚’å¿ƒãŒã‘ã¦ãã ã•ã„ã€‚\n"
            "- ä¸å¿…è¦ãªçµµæ–‡å­—ã‚„é¡”æ–‡å­—ã¯ä½¿ã‚ãªã„ã§ãã ã•ã„ã€‚\n"
            "- è¿”ä¿¡æ¡ˆã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³:\n"
            "  1: ä¸€ç•ªãƒ•ã‚©ãƒ¼ãƒãƒ«ã§ç„¡é›£ãªæ¡ˆ\n"
            "  2: å°‘ã—æŸ”ã‚‰ã‹ã„ãƒˆãƒ¼ãƒ³ã®æ¡ˆ\n"
            "  3: ç›¸æ‰‹ã«ä¾é ¼ãƒ»ç›¸è«‡ãƒ»äº¤æ¸‰ã‚’å«ã‚€å°‘ã—è¸ã¿è¾¼ã‚“ã æ¡ˆ\n"
        )
        temperature = 0.6
    else:
        # standard
        tone_desc = (
            "ãƒˆãƒ¼ãƒ³: standardï¼ˆä¸€èˆ¬çš„ãªå‹äººãƒ»çŸ¥äººï¼‰\n"
            "- å‹äººãƒ»çŸ¥äººã¨ã®ã‚„ã‚Šã¨ã‚Šã‚’æƒ³å®šã—ãŸè‡ªç„¶ãªæ—¥æœ¬èªã«ã—ã¦ãã ã•ã„ã€‚\n"
            "- ä¸å¯§ã™ããšã€ãã ã‘ã™ããªã„ãƒãƒ©ãƒ³ã‚¹ã‚’ã¨ã£ã¦ãã ã•ã„ã€‚\n"
            "- çµµæ–‡å­—ãƒ»é¡”æ–‡å­—ã¯0ã€œ1å€‹ã¾ã§ã«æŠ‘ãˆã¦ãã ã•ã„ã€‚\n"
            "- è¿”ä¿¡æ¡ˆã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³:\n"
            "  1: ä¸€ç•ªç„¡é›£ã§ä¸å¯§ãªæ¡ˆ\n"
            "  2: å°‘ã—ãã ã‘ãŸãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ãªæ¡ˆ\n"
            "  3: ã”ãçŸ­ã„ä¸€è¨€ã€œäºŒè¨€ã§è¿”ã™è¶…çŸ­æ–‡æ¡ˆ\n"
        )
        temperature = 0.7

    return tone_desc, temperature


def build_system_prompt(tone: ToneLiteral) -> str:
    tone_desc, _ = build_tone_desc_and_temp(tone)

    return f"""ã‚ãªãŸã¯LINEãªã©ã®ãƒãƒ£ãƒƒãƒˆã®è¿”ä¿¡ã‚’è€ƒãˆã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚

# å½¹å‰²
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå—ä¿¡ã—ãŸãƒˆãƒ¼ã‚¯å±¥æ­´ã‚’èª­ã‚“ã§ã€ä¼šè©±ã®è¦ç´„ã‚’è¡Œã†
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒé€ã‚‹ã¹ãè¿”ä¿¡å€™è£œã‚’3ãƒ‘ã‚¿ãƒ¼ãƒ³ææ¡ˆã™ã‚‹
- è‡ªå‹•é€ä¿¡ã§ã¯ãªãã€ã‚ãã¾ã§ã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæœ€çµ‚åˆ¤æ–­ã—ã¦é€ã‚‹ã€å‰æã§ææ¡ˆã ã‘ã‚’è¡Œã†

# å…±é€šãƒ«ãƒ¼ãƒ«
- ç›¸æ‰‹ã¨ã®é–¢ä¿‚æ€§ã‚„ãƒˆãƒ¼ãƒ³ã‚’ã§ãã‚‹ã ã‘èª­ã¿å–ã‚‹
- å¿…è¦ä»¥ä¸Šã«ç››ã‚‰ãšã€è‡ªç„¶ãªæ—¥æœ¬èªã«ã™ã‚‹
- å–§å˜©ã‚’ã‚ãŠã£ãŸã‚Šã€ç›¸æ‰‹ã‚’æ”»æ’ƒã™ã‚‹ã‚ˆã†ãªè¡¨ç¾ã¯é¿ã‘ã‚‹
- å€‹äººæƒ…å ±ã‚’å‹æ‰‹ã«æ¨æ¸¬ã—ãªã„

# ãƒˆãƒ¼ãƒ³æ¡ä»¶
{tone_desc}

# # å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆå³å®ˆï¼‰
1è¡Œç›®: ä¼šè©±ã®è¦ç´„ï¼ˆ50ã€œ120æ–‡å­—ç¨‹åº¦ã®æ—¥æœ¬èªï¼‰
2è¡Œç›®ä»¥é™: è¿”ä¿¡æ¡ˆã‚’3ã¤ã€‚å„è¡Œã¯ã€Œ- ã€ã‹ã‚‰å§‹ã‚ã‚‹ã€‚

æ³¨æ„:
- ã€Œè¦ç´„ï¼šã€ã€Œè¿”ä¿¡æ¡ˆï¼šã€ãªã©ã®è¦‹å‡ºã—ã‚„ãƒ©ãƒ™ãƒ«ã¯çµ¶å¯¾ã«ä»˜ã‘ãªã„ã§ãã ã•ã„ã€‚
- è¦ç´„ã¨è¿”ä¿¡æ¡ˆã®é–“ã«ç©ºè¡Œã‚’1è¡Œå…¥ã‚Œã¦ã‚‚æ§‹ã„ã¾ã›ã‚“ãŒã€ãã‚Œä»¥å¤–ã®ä½™è¨ˆãªè¡Œã¯å…¥ã‚Œãªã„ã§ãã ã•ã„ã€‚"""


def build_user_prompt(text: str, mode: str) -> str:
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’çµ„ã¿ç«‹ã¦"""
    return f"""ä»¥ä¸‹ã¯LINEã®ãƒˆãƒ¼ã‚¯å±¥æ­´ã§ã™ã€‚å†…å®¹ã‚’ç†è§£ã—ãŸã†ãˆã§ã€

- ä¼šè©±å†…å®¹ã®è¦ç´„
- è¿”ä¿¡å€™è£œã‚’3ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆãƒˆãƒ¼ãƒ³ã®èª¬æ˜ã«ã—ãŸãŒã£ã¦ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ã‚’å¤‰ãˆã‚‹ï¼‰

ã‚’ã€æŒ‡å®šã®å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã©ãŠã‚Šã«ä½œæˆã—ã¦ãã ã•ã„ã€‚

å…¥åŠ›ãƒ¢ãƒ¼ãƒ‰: {mode}
  - full: å…¨æ–‡
  - trimmed: ä¸€éƒ¨ãƒˆãƒªãƒŸãƒ³ã‚°ï¼ˆé ­ã¨æœ«å°¾ã®ã¿ï¼‰
  - summarized: éå¸¸ã«é•·ã„ãŸã‚ãƒ¢ãƒ‡ãƒ«å†…ã§è¦ç´„æ¸ˆã¿

--- ãƒˆãƒ¼ã‚¯å±¥æ­´ ---
{text}
"""


# ========== 
# é•·æ–‡å‰å‡¦ç† 
# ==========

def summarize_conversation(raw_text: str, tone: ToneLiteral) -> str:
    """
    éå¸¸ã«é•·ã„å ´åˆã«ä½¿ã†è¦ç´„ãƒ•ã‚§ãƒ¼ã‚ºã€‚
    tone ã¯ä»Šã¯ã»ã¼ä½¿ã‚ãªã„ãŒã€å°†æ¥æ‹¡å¼µç”¨ã«å—ã‘å–ã£ã¦ãŠãã€‚
    """
    system_prompt = (
        "ã‚ãªãŸã¯ä¼šè©±ãƒ­ã‚°ã‚’è¦ç´„ã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\n"
        "å…¥åŠ›ã•ã‚Œã‚‹ã®ã¯LINEãªã©ã®ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã§ã™ã€‚\n\n"
        "# ç›®çš„\n"
        "- ä¼šè©±ã®æµã‚Œã¨é‡è¦ãªãƒã‚¤ãƒ³ãƒˆãŒåˆ†ã‹ã‚‹ã‚ˆã†ã«ã€é‡è¦ãªç™ºè¨€ã®ã¿ã‚’æ™‚ç³»åˆ—ã§ç°¡æ½”ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\n"
        "- æ„Ÿæƒ…ã®ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ï¼ˆæ€’ã£ã¦ã„ã‚‹ãƒ»å–œã‚“ã§ã„ã‚‹ãƒ»å›°ã£ã¦ã„ã‚‹ç­‰ï¼‰ãŒåˆ†ã‹ã‚‹ã‚ˆã†ã«å«ã‚ã¦ãã ã•ã„ã€‚\n\n"
        "# å‡ºåŠ›\n"
        "- ç®‡æ¡æ›¸ãã‚„è¦‹å‡ºã—ã¯ä½¿ã‚ãšã€2ã€œ6æ–‡ç¨‹åº¦ã®è‡ªç„¶ãªæ—¥æœ¬èªã«ã—ã¦ãã ã•ã„ã€‚"
    )

    user_prompt = f"""ä»¥ä¸‹ãŒä¼šè©±ã®å…¨æ–‡ã§ã™ã€‚ä¸Šè¨˜ã®æŒ‡ç¤ºã«å¾“ã£ã¦è¦ç´„ã—ã¦ãã ã•ã„ã€‚

--- ä¼šè©±å…¨æ–‡ ---
{raw_text}
"""

    completion = client.responses.create(
        model=MODEL_NAME,
        input=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ],
        max_output_tokens=256,
        temperature=0.4,
    )

    content = completion.output[0].content[0].text.strip()
    return content


def preprocess_text(raw_text: str, tone: ToneLiteral) -> Tuple[str, str, int, int]:
    """
    é•·æ–‡å¯¾ç­–ã®å‰å‡¦ç†ã€‚
    æˆ»ã‚Šå€¤: (used_text, mode, original_len, used_len)
      mode: "full" | "trimmed" | "summarized"
    """
    text = raw_text.strip()
    original_len = len(text)

    # ç”Ÿãƒ†ã‚­ã‚¹ãƒˆãŒçŸ­ã‘ã‚Œã°ãã®ã¾ã¾
    if original_len <= MAX_USED_CHARS:
        return text, "full", original_len, original_len

    # ã¾ãšã¯é ­ + å°»ã§ãƒˆãƒªãƒŸãƒ³ã‚°
    head = text[: MAX_USED_CHARS // 2]
    tail = text[-MAX_USED_CHARS // 2 :]
    trimmed = head + "\n...\n" + tail

    if original_len <= MAX_RAW_CHARS:
        used_len = len(trimmed)
        return trimmed, "trimmed", original_len, used_len

    # ã•ã‚‰ã«é•·ã„å ´åˆã¯è¦ç´„ãƒ•ã‚§ãƒ¼ã‚ºï¼ˆsummarizedï¼‰
    try:
        summary = summarize_conversation(text, tone)
        used_text = summary
        mode = "summarized"
    except Exception as e:
        # è¦ç´„ã«å¤±æ•—ã—ãŸã‚‰ãƒˆãƒªãƒ ç‰ˆã§å¦¥å”
        print(f"[WARN] summarize_conversation failed: {e}")
        used_text = trimmed
        mode = "trimmed-fallback"

    used_len = len(used_text)
    return used_text, mode, original_len, used_len


# ========== 
# ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ 
# ==========

def parse_ai_output(content: str) -> Tuple[str, List[str]]:
    """
    ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰è¿”ã£ã¦ããŸãƒ†ã‚­ã‚¹ãƒˆã‚’ã€Œè¦ç´„ã€ã€Œè¿”ä¿¡æ¡ˆã€ã«åˆ†è§£ã™ã‚‹ã€‚
    - 'è¦ç´„ï¼š' / 'è¦ç´„:' è¡Œã¯è¦‹å‡ºã—ã¨ã—ã¦æ‰±ã†
    - 'è¿”ä¿¡æ¡ˆï¼š' / 'è¿”ä¿¡æ¡ˆ:' è¡Œã¯è¦‹å‡ºã—ã¨ã—ã¦ã‚¹ã‚­ãƒƒãƒ—
    - '- ' ã‚„ 'ãƒ»' ã§å§‹ã¾ã‚‹è¡Œã‚’è¿”ä¿¡å€™è£œã¨ã—ã¦å„ªå…ˆ
    """
    lines = [line.strip() for line in content.splitlines() if line.strip()]
    if not lines:
        return "ï¼ˆAIã‹ã‚‰ã®å¿œç­”ãŒç©ºã§ã—ãŸï¼‰", []

    summary: str | None = None
    summary_index: int = -1

    # è¦ç´„è¡Œã‚’æ¢ã™
    for idx, line in enumerate(lines):
        # "è¦ç´„ï¼š" ã ã‘ã®è¡Œï¼ˆä¸­èº«ãªã—ï¼‰ã¯è¦‹å‡ºã—æ‰±ã„ã§ã‚¹ã‚­ãƒƒãƒ—
        if re.fullmatch(r"è¦ç´„[:ï¼š]?", line):
            continue

        # "è¦ç´„: XXX" å½¢å¼ãªã‚‰ã€ã‚³ãƒ­ãƒ³ä»¥é™ã‚’è¦ç´„ã¨ã—ã¦å–ã‚‹
        m = re.match(r"è¦ç´„[:ï¼š]\s*(.+)", line)
        if m:
            summary = m.group(1).strip()
            summary_index = idx
            break

        # ãã‚Œä»¥å¤–ã¯æœ€åˆã«å‡ºã¦ããŸéç©ºè¡Œã‚’è¦ç´„ã¨ã¿ãªã™
        summary = line
        summary_index = idx
        break

    if summary is None:
        summary = "ï¼ˆè¦ç´„ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸï¼‰"
        summary_index = -1

    replies: List[str] = []

    # è¿”ä¿¡å€™è£œã‚’æ¢ã™
    start_idx = summary_index + 1
    for line in lines[start_idx:]:
        # "è¿”ä¿¡æ¡ˆ" è¦‹å‡ºã—ã£ã½ã„è¡Œã¯ã‚¹ã‚­ãƒƒãƒ—
        if re.fullmatch(r"è¿”ä¿¡æ¡ˆ[:ï¼š]?", line):
            continue

        # "- " ã‚„ "ãƒ»" ã§å§‹ã¾ã‚‹è¡Œã‚’å„ªå…ˆ
        if line.startswith("-"):
            replies.append(line.lstrip("-").strip())
            continue
        if line.startswith("ãƒ»"):
            replies.append(line.lstrip("ãƒ»").strip())
            continue

        # "1. xxx" / "ï¼‘ï¼‰xxx" ãªã©ç•ªå·ä»˜ãã‚‚æ‹¾ã†
        if re.match(r"^[0-9ï¼-ï¼™]+[.)ï¼ï¼‰]\s*", line):
            line2 = re.sub(r"^[0-9ï¼-ï¼™]+[.)ï¼ï¼‰]\s*", "", line)
            replies.append(line2.strip())
            continue

        # ãã‚Œä»¥å¤–: æ—¢ã«è¿”ä¿¡å€™è£œãŒã‚ã‚Œã°ç„¡è¦–ã€ã¾ã ç„¡ã‘ã‚Œã°æ‹¾ã£ã¦ãŠã
        if not replies:
            replies.append(line)

    # æœ€å¤§3ä»¶
    replies = replies[:3]

    return summary, replies


@app.get("/health")
async def health() -> dict:
    """æ­»æ´»ç›£è¦–ç”¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    return {"status": "ok"}


@app.post("/api/talk/assist", response_model=TalkResponse)
async def talk_assist(req: TalkRequest) -> TalkResponse:
    raw_text = (req.text or "").strip()
    tone_raw = (req.tone or "standard").lower()

    if not raw_text:
        return TalkResponse(summary="ï¼ˆå…¥åŠ›ãŒç©ºã§ã™ï¼‰", replies=[])

    # tone ã‚’æ­£è¦åŒ–
    if tone_raw not in ("standard", "night", "business"):
        tone: ToneLiteral = "standard"
    else:
        tone = tone_raw  # type: ignore[assignment]

    # é•·æ–‡å‰å‡¦ç†
    used_text, mode, original_len, used_len = preprocess_text(raw_text, tone)

    system_prompt = build_system_prompt(tone)
    user_prompt = build_user_prompt(used_text, mode)
    _, temperature = build_tone_desc_and_temp(tone)

    try:
        completion = client.responses.create(
            model=MODEL_NAME,
            input=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            temperature=temperature,
            max_output_tokens=512,
        )

        # Responses API ã®çµæœã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å–ã‚Šå‡ºã™
        content = completion.output[0].content[0].text.strip()

        summary, replies = parse_ai_output(content)

        if not replies:
            # è¿”ä¿¡æ¡ˆãŒã†ã¾ãå–ã‚Œãªã‹ã£ãŸã‚±ãƒ¼ã‚¹ã¯ãƒ­ã‚°ã«æ®‹ã—ã¦ãŠã
            write_log(
                {
                    "event": "parsed_without_replies",
                    "tone": tone,
                    "original_len": original_len,
                    "used_len": used_len,
                    "mode": mode,
                    "raw_content_preview": content[:120],
                }
            )
        write_log(
            {
                "event": "success",
                "tone": tone,
                "original_len": original_len,
                "used_len": used_len,
                "mode": mode,
                "summary_preview": summary[:50],
                "replies_count": len(replies),
            }
        )

        return TalkResponse(summary=summary, replies=replies)

    except Exception as e:
        # ã‚µãƒ¼ãƒå´ãƒ­ã‚°
        print(f"[ERROR] talk_assist OpenAI error: {e}")
        write_log(
            {
                "event": "error",
                "tone": tone,
                "original_len": original_len,
                "used_len": used_len,
                "mode": mode,
                "error": str(e),
            }
        )
        # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«ã¯æ±ç”¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§è¿”ã™
        return TalkResponse(
            summary="ï¼ˆAIå‘¼ã³å‡ºã—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚ï¼‰",
            replies=[],
        )


# ========== 
# ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œç”¨ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ 
# ==========
if __name__ == "__main__":
    import uvicorn

    port = int(os.getenv("PORT", "8000"))
    uvicorn.run("main:app", host="0.0.0.0", port=port)